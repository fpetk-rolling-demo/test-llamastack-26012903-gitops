# Llama Stack Server Deployment
# run.yaml is baked into the image - env vars override config at runtime
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "2"
  labels:
    app.kubernetes.io/instance: test-llamastack-26012903-llama-stack
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/name: test-llamastack-26012903-llama-stack
    app.kubernetes.io/part-of: test-llamastack-26012903
    app.kubernetes.io/component: llama-stack
  name: test-llamastack-26012903-llama-stack
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: test-llamastack-26012903-llama-stack
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: test-llamastack-26012903-llama-stack
        app.kubernetes.io/component: llama-stack
    spec:
      containers:
        - name: llama-stack
          # Image with run.yaml baked in
          image: quay.io/tpetkos/test-llamastack-26012903:76823fcdc84a419c7f23aafa3e0d60925a358267
          imagePullPolicy: Always
          envFrom:
            # Non-sensitive config from template (URLs, model names)
            - configMapRef:
                name: test-llamastack-26012903-llama-stack-env
            # Sensitive config from user-created secret (API keys)
            - secretRef:
                name: llama-stack-secrets
                optional: false
          env:
            # Explicitly set provider URLs and keys (also in ConfigMap/Secret via envFrom,
            # but duplicated here to ensure availability during early initialization)
            - name: VLLM_URL
              valueFrom:
                configMapKeyRef:
                  name: test-llamastack-26012903-llama-stack-env
                  key: VLLM_URL
            - name: VLLM_API_KEY
              valueFrom:
                secretKeyRef:
                  name: llama-stack-secrets
                  key: VLLM_API_KEY
            - name: OLLAMA_URL
              valueFrom:
                configMapKeyRef:
                  name: test-llamastack-26012903-llama-stack-env
                  key: OLLAMA_URL
            # Override paths for container environment
            - name: KV_SQL_STORE_DIR
              value: "/data"
            - name: SQLITE_STORE_DIR
              value: "/data"
            - name: FILES_STORAGE_DIR
              value: "/data/files"
            # MCP Server URL for tool runtime
            - name: MCP_SERVER_URL
              value: "http://test-llamastack-26012903-mcp-server:8080"
          ports:
            - containerPort: 8321
              name: http
              protocol: TCP
          resources:
            requests:
              memory: "2Gi"
              cpu: "500m"
            limits:
              memory: "8Gi"
              cpu: "2000m"
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
                - ALL
          readinessProbe:
            httpGet:
              path: /v1/health
              port: 8321
            initialDelaySeconds: 30
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /v1/health
              port: 8321
            initialDelaySeconds: 60
            periodSeconds: 30
          volumeMounts:
            - name: llama-data
              mountPath: /data
      volumes:
        - name: llama-data
          # Ephemeral storage for faiss indexes and sqlite stores
          # Data is lost on pod restart
          # For production with persistent RAG data, consider using a PVC instead
          emptyDir: {}

